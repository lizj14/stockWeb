


<!DOCTYPE html>
<html>
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
    
    
    <meta http-equiv="X-UA-Compatible" content="IE=emulateIE7" />
    <title>Coverage for /home/ec2-user/environment/venv/py3vir/lib/python3.6/dist-packages/keras_applications/resnet50.py: 13%</title>
    <link rel="stylesheet" href="style.css" type="text/css">
    
    <script type="text/javascript" src="jquery.min.js"></script>
    <script type="text/javascript" src="jquery.hotkeys.js"></script>
    <script type="text/javascript" src="jquery.isonscreen.js"></script>
    <script type="text/javascript" src="coverage_html.js"></script>
    <script type="text/javascript">
        jQuery(document).ready(coverage.pyfile_ready);
    </script>
</head>
<body class="pyfile">

<div id="header">
    <div class="content">
        <h1>Coverage for <b>/home/ec2-user/environment/venv/py3vir/lib/python3.6/dist-packages/keras_applications/resnet50.py</b> :
            <span class="pc_cov">13%</span>
        </h1>

        <img id="keyboard_icon" src="keybd_closed.png" alt="Show keyboard shortcuts" />

        <h2 class="stats">
            113 statements &nbsp;
            <span class="run hide_run shortkey_r button_toggle_run">19 run</span>
            <span class="mis shortkey_m button_toggle_mis">94 missing</span>
            <span class="exc shortkey_x button_toggle_exc">0 excluded</span>

            
                <span class="par run hide_run shortkey_p button_toggle_par">0 partial</span>
            
        </h2>
    </div>
</div>

<div class="help_panel">
    <img id="panel_icon" src="keybd_open.png" alt="Hide keyboard shortcuts" />
    <p class="legend">Hot-keys on this page</p>
    <div>
    <p class="keyhelp">
        <span class="key">r</span>
        <span class="key">m</span>
        <span class="key">x</span>
        <span class="key">p</span> &nbsp; toggle line displays
    </p>
    <p class="keyhelp">
        <span class="key">j</span>
        <span class="key">k</span> &nbsp; next/prev highlighted chunk
    </p>
    <p class="keyhelp">
        <span class="key">0</span> &nbsp; (zero) top of page
    </p>
    <p class="keyhelp">
        <span class="key">1</span> &nbsp; (one) first highlighted chunk
    </p>
    </div>
</div>

<div id="source">
    <table>
        <tr>
            <td class="linenos">
<p id="n1" class="pln"><a href="#n1">1</a></p>
<p id="n2" class="pln"><a href="#n2">2</a></p>
<p id="n3" class="pln"><a href="#n3">3</a></p>
<p id="n4" class="pln"><a href="#n4">4</a></p>
<p id="n5" class="pln"><a href="#n5">5</a></p>
<p id="n6" class="pln"><a href="#n6">6</a></p>
<p id="n7" class="pln"><a href="#n7">7</a></p>
<p id="n8" class="pln"><a href="#n8">8</a></p>
<p id="n9" class="pln"><a href="#n9">9</a></p>
<p id="n10" class="stm run hide_run"><a href="#n10">10</a></p>
<p id="n11" class="stm run hide_run"><a href="#n11">11</a></p>
<p id="n12" class="stm run hide_run"><a href="#n12">12</a></p>
<p id="n13" class="pln"><a href="#n13">13</a></p>
<p id="n14" class="stm run hide_run"><a href="#n14">14</a></p>
<p id="n15" class="stm run hide_run"><a href="#n15">15</a></p>
<p id="n16" class="pln"><a href="#n16">16</a></p>
<p id="n17" class="stm run hide_run"><a href="#n17">17</a></p>
<p id="n18" class="stm run hide_run"><a href="#n18">18</a></p>
<p id="n19" class="stm run hide_run"><a href="#n19">19</a></p>
<p id="n20" class="stm run hide_run"><a href="#n20">20</a></p>
<p id="n21" class="pln"><a href="#n21">21</a></p>
<p id="n22" class="stm run hide_run"><a href="#n22">22</a></p>
<p id="n23" class="pln"><a href="#n23">23</a></p>
<p id="n24" class="stm run hide_run"><a href="#n24">24</a></p>
<p id="n25" class="pln"><a href="#n25">25</a></p>
<p id="n26" class="pln"><a href="#n26">26</a></p>
<p id="n27" class="stm run hide_run"><a href="#n27">27</a></p>
<p id="n28" class="pln"><a href="#n28">28</a></p>
<p id="n29" class="pln"><a href="#n29">29</a></p>
<p id="n30" class="pln"><a href="#n30">30</a></p>
<p id="n31" class="stm run hide_run"><a href="#n31">31</a></p>
<p id="n32" class="stm run hide_run"><a href="#n32">32</a></p>
<p id="n33" class="stm run hide_run"><a href="#n33">33</a></p>
<p id="n34" class="stm run hide_run"><a href="#n34">34</a></p>
<p id="n35" class="pln"><a href="#n35">35</a></p>
<p id="n36" class="pln"><a href="#n36">36</a></p>
<p id="n37" class="stm run hide_run"><a href="#n37">37</a></p>
<p id="n38" class="pln"><a href="#n38">38</a></p>
<p id="n39" class="pln"><a href="#n39">39</a></p>
<p id="n40" class="pln"><a href="#n40">40</a></p>
<p id="n41" class="pln"><a href="#n41">41</a></p>
<p id="n42" class="pln"><a href="#n42">42</a></p>
<p id="n43" class="pln"><a href="#n43">43</a></p>
<p id="n44" class="pln"><a href="#n44">44</a></p>
<p id="n45" class="pln"><a href="#n45">45</a></p>
<p id="n46" class="pln"><a href="#n46">46</a></p>
<p id="n47" class="pln"><a href="#n47">47</a></p>
<p id="n48" class="pln"><a href="#n48">48</a></p>
<p id="n49" class="pln"><a href="#n49">49</a></p>
<p id="n50" class="pln"><a href="#n50">50</a></p>
<p id="n51" class="stm mis"><a href="#n51">51</a></p>
<p id="n52" class="stm mis"><a href="#n52">52</a></p>
<p id="n53" class="stm mis"><a href="#n53">53</a></p>
<p id="n54" class="pln"><a href="#n54">54</a></p>
<p id="n55" class="stm mis"><a href="#n55">55</a></p>
<p id="n56" class="stm mis"><a href="#n56">56</a></p>
<p id="n57" class="stm mis"><a href="#n57">57</a></p>
<p id="n58" class="pln"><a href="#n58">58</a></p>
<p id="n59" class="stm mis"><a href="#n59">59</a></p>
<p id="n60" class="pln"><a href="#n60">60</a></p>
<p id="n61" class="pln"><a href="#n61">61</a></p>
<p id="n62" class="stm mis"><a href="#n62">62</a></p>
<p id="n63" class="stm mis"><a href="#n63">63</a></p>
<p id="n64" class="pln"><a href="#n64">64</a></p>
<p id="n65" class="stm mis"><a href="#n65">65</a></p>
<p id="n66" class="pln"><a href="#n66">66</a></p>
<p id="n67" class="pln"><a href="#n67">67</a></p>
<p id="n68" class="pln"><a href="#n68">68</a></p>
<p id="n69" class="stm mis"><a href="#n69">69</a></p>
<p id="n70" class="stm mis"><a href="#n70">70</a></p>
<p id="n71" class="pln"><a href="#n71">71</a></p>
<p id="n72" class="stm mis"><a href="#n72">72</a></p>
<p id="n73" class="pln"><a href="#n73">73</a></p>
<p id="n74" class="pln"><a href="#n74">74</a></p>
<p id="n75" class="stm mis"><a href="#n75">75</a></p>
<p id="n76" class="pln"><a href="#n76">76</a></p>
<p id="n77" class="stm mis"><a href="#n77">77</a></p>
<p id="n78" class="stm mis"><a href="#n78">78</a></p>
<p id="n79" class="stm mis"><a href="#n79">79</a></p>
<p id="n80" class="pln"><a href="#n80">80</a></p>
<p id="n81" class="pln"><a href="#n81">81</a></p>
<p id="n82" class="stm run hide_run"><a href="#n82">82</a></p>
<p id="n83" class="pln"><a href="#n83">83</a></p>
<p id="n84" class="pln"><a href="#n84">84</a></p>
<p id="n85" class="pln"><a href="#n85">85</a></p>
<p id="n86" class="pln"><a href="#n86">86</a></p>
<p id="n87" class="pln"><a href="#n87">87</a></p>
<p id="n88" class="pln"><a href="#n88">88</a></p>
<p id="n89" class="pln"><a href="#n89">89</a></p>
<p id="n90" class="pln"><a href="#n90">90</a></p>
<p id="n91" class="pln"><a href="#n91">91</a></p>
<p id="n92" class="pln"><a href="#n92">92</a></p>
<p id="n93" class="pln"><a href="#n93">93</a></p>
<p id="n94" class="pln"><a href="#n94">94</a></p>
<p id="n95" class="pln"><a href="#n95">95</a></p>
<p id="n96" class="pln"><a href="#n96">96</a></p>
<p id="n97" class="pln"><a href="#n97">97</a></p>
<p id="n98" class="pln"><a href="#n98">98</a></p>
<p id="n99" class="pln"><a href="#n99">99</a></p>
<p id="n100" class="pln"><a href="#n100">100</a></p>
<p id="n101" class="pln"><a href="#n101">101</a></p>
<p id="n102" class="pln"><a href="#n102">102</a></p>
<p id="n103" class="pln"><a href="#n103">103</a></p>
<p id="n104" class="pln"><a href="#n104">104</a></p>
<p id="n105" class="pln"><a href="#n105">105</a></p>
<p id="n106" class="stm mis"><a href="#n106">106</a></p>
<p id="n107" class="stm mis"><a href="#n107">107</a></p>
<p id="n108" class="stm mis"><a href="#n108">108</a></p>
<p id="n109" class="pln"><a href="#n109">109</a></p>
<p id="n110" class="stm mis"><a href="#n110">110</a></p>
<p id="n111" class="stm mis"><a href="#n111">111</a></p>
<p id="n112" class="stm mis"><a href="#n112">112</a></p>
<p id="n113" class="pln"><a href="#n113">113</a></p>
<p id="n114" class="stm mis"><a href="#n114">114</a></p>
<p id="n115" class="pln"><a href="#n115">115</a></p>
<p id="n116" class="pln"><a href="#n116">116</a></p>
<p id="n117" class="stm mis"><a href="#n117">117</a></p>
<p id="n118" class="stm mis"><a href="#n118">118</a></p>
<p id="n119" class="pln"><a href="#n119">119</a></p>
<p id="n120" class="stm mis"><a href="#n120">120</a></p>
<p id="n121" class="pln"><a href="#n121">121</a></p>
<p id="n122" class="pln"><a href="#n122">122</a></p>
<p id="n123" class="stm mis"><a href="#n123">123</a></p>
<p id="n124" class="stm mis"><a href="#n124">124</a></p>
<p id="n125" class="pln"><a href="#n125">125</a></p>
<p id="n126" class="stm mis"><a href="#n126">126</a></p>
<p id="n127" class="pln"><a href="#n127">127</a></p>
<p id="n128" class="pln"><a href="#n128">128</a></p>
<p id="n129" class="stm mis"><a href="#n129">129</a></p>
<p id="n130" class="pln"><a href="#n130">130</a></p>
<p id="n131" class="stm mis"><a href="#n131">131</a></p>
<p id="n132" class="pln"><a href="#n132">132</a></p>
<p id="n133" class="pln"><a href="#n133">133</a></p>
<p id="n134" class="stm mis"><a href="#n134">134</a></p>
<p id="n135" class="pln"><a href="#n135">135</a></p>
<p id="n136" class="pln"><a href="#n136">136</a></p>
<p id="n137" class="stm mis"><a href="#n137">137</a></p>
<p id="n138" class="stm mis"><a href="#n138">138</a></p>
<p id="n139" class="stm mis"><a href="#n139">139</a></p>
<p id="n140" class="pln"><a href="#n140">140</a></p>
<p id="n141" class="pln"><a href="#n141">141</a></p>
<p id="n142" class="stm run hide_run"><a href="#n142">142</a></p>
<p id="n143" class="pln"><a href="#n143">143</a></p>
<p id="n144" class="pln"><a href="#n144">144</a></p>
<p id="n145" class="pln"><a href="#n145">145</a></p>
<p id="n146" class="pln"><a href="#n146">146</a></p>
<p id="n147" class="pln"><a href="#n147">147</a></p>
<p id="n148" class="pln"><a href="#n148">148</a></p>
<p id="n149" class="pln"><a href="#n149">149</a></p>
<p id="n150" class="pln"><a href="#n150">150</a></p>
<p id="n151" class="pln"><a href="#n151">151</a></p>
<p id="n152" class="pln"><a href="#n152">152</a></p>
<p id="n153" class="pln"><a href="#n153">153</a></p>
<p id="n154" class="pln"><a href="#n154">154</a></p>
<p id="n155" class="pln"><a href="#n155">155</a></p>
<p id="n156" class="pln"><a href="#n156">156</a></p>
<p id="n157" class="pln"><a href="#n157">157</a></p>
<p id="n158" class="pln"><a href="#n158">158</a></p>
<p id="n159" class="pln"><a href="#n159">159</a></p>
<p id="n160" class="pln"><a href="#n160">160</a></p>
<p id="n161" class="pln"><a href="#n161">161</a></p>
<p id="n162" class="pln"><a href="#n162">162</a></p>
<p id="n163" class="pln"><a href="#n163">163</a></p>
<p id="n164" class="pln"><a href="#n164">164</a></p>
<p id="n165" class="pln"><a href="#n165">165</a></p>
<p id="n166" class="pln"><a href="#n166">166</a></p>
<p id="n167" class="pln"><a href="#n167">167</a></p>
<p id="n168" class="pln"><a href="#n168">168</a></p>
<p id="n169" class="pln"><a href="#n169">169</a></p>
<p id="n170" class="pln"><a href="#n170">170</a></p>
<p id="n171" class="pln"><a href="#n171">171</a></p>
<p id="n172" class="pln"><a href="#n172">172</a></p>
<p id="n173" class="pln"><a href="#n173">173</a></p>
<p id="n174" class="pln"><a href="#n174">174</a></p>
<p id="n175" class="pln"><a href="#n175">175</a></p>
<p id="n176" class="pln"><a href="#n176">176</a></p>
<p id="n177" class="pln"><a href="#n177">177</a></p>
<p id="n178" class="pln"><a href="#n178">178</a></p>
<p id="n179" class="pln"><a href="#n179">179</a></p>
<p id="n180" class="pln"><a href="#n180">180</a></p>
<p id="n181" class="pln"><a href="#n181">181</a></p>
<p id="n182" class="pln"><a href="#n182">182</a></p>
<p id="n183" class="pln"><a href="#n183">183</a></p>
<p id="n184" class="pln"><a href="#n184">184</a></p>
<p id="n185" class="pln"><a href="#n185">185</a></p>
<p id="n186" class="pln"><a href="#n186">186</a></p>
<p id="n187" class="pln"><a href="#n187">187</a></p>
<p id="n188" class="pln"><a href="#n188">188</a></p>
<p id="n189" class="pln"><a href="#n189">189</a></p>
<p id="n190" class="pln"><a href="#n190">190</a></p>
<p id="n191" class="pln"><a href="#n191">191</a></p>
<p id="n192" class="pln"><a href="#n192">192</a></p>
<p id="n193" class="stm mis"><a href="#n193">193</a></p>
<p id="n194" class="pln"><a href="#n194">194</a></p>
<p id="n195" class="stm mis"><a href="#n195">195</a></p>
<p id="n196" class="stm mis"><a href="#n196">196</a></p>
<p id="n197" class="pln"><a href="#n197">197</a></p>
<p id="n198" class="pln"><a href="#n198">198</a></p>
<p id="n199" class="pln"><a href="#n199">199</a></p>
<p id="n200" class="pln"><a href="#n200">200</a></p>
<p id="n201" class="stm mis"><a href="#n201">201</a></p>
<p id="n202" class="stm mis"><a href="#n202">202</a></p>
<p id="n203" class="pln"><a href="#n203">203</a></p>
<p id="n204" class="pln"><a href="#n204">204</a></p>
<p id="n205" class="pln"><a href="#n205">205</a></p>
<p id="n206" class="stm mis"><a href="#n206">206</a></p>
<p id="n207" class="pln"><a href="#n207">207</a></p>
<p id="n208" class="pln"><a href="#n208">208</a></p>
<p id="n209" class="pln"><a href="#n209">209</a></p>
<p id="n210" class="pln"><a href="#n210">210</a></p>
<p id="n211" class="pln"><a href="#n211">211</a></p>
<p id="n212" class="pln"><a href="#n212">212</a></p>
<p id="n213" class="stm mis"><a href="#n213">213</a></p>
<p id="n214" class="stm mis"><a href="#n214">214</a></p>
<p id="n215" class="pln"><a href="#n215">215</a></p>
<p id="n216" class="stm mis"><a href="#n216">216</a></p>
<p id="n217" class="stm mis"><a href="#n217">217</a></p>
<p id="n218" class="pln"><a href="#n218">218</a></p>
<p id="n219" class="stm mis"><a href="#n219">219</a></p>
<p id="n220" class="stm mis"><a href="#n220">220</a></p>
<p id="n221" class="stm mis"><a href="#n221">221</a></p>
<p id="n222" class="pln"><a href="#n222">222</a></p>
<p id="n223" class="stm mis"><a href="#n223">223</a></p>
<p id="n224" class="pln"><a href="#n224">224</a></p>
<p id="n225" class="stm mis"><a href="#n225">225</a></p>
<p id="n226" class="stm mis"><a href="#n226">226</a></p>
<p id="n227" class="pln"><a href="#n227">227</a></p>
<p id="n228" class="pln"><a href="#n228">228</a></p>
<p id="n229" class="pln"><a href="#n229">229</a></p>
<p id="n230" class="pln"><a href="#n230">230</a></p>
<p id="n231" class="stm mis"><a href="#n231">231</a></p>
<p id="n232" class="stm mis"><a href="#n232">232</a></p>
<p id="n233" class="stm mis"><a href="#n233">233</a></p>
<p id="n234" class="stm mis"><a href="#n234">234</a></p>
<p id="n235" class="pln"><a href="#n235">235</a></p>
<p id="n236" class="stm mis"><a href="#n236">236</a></p>
<p id="n237" class="stm mis"><a href="#n237">237</a></p>
<p id="n238" class="stm mis"><a href="#n238">238</a></p>
<p id="n239" class="pln"><a href="#n239">239</a></p>
<p id="n240" class="stm mis"><a href="#n240">240</a></p>
<p id="n241" class="stm mis"><a href="#n241">241</a></p>
<p id="n242" class="stm mis"><a href="#n242">242</a></p>
<p id="n243" class="stm mis"><a href="#n243">243</a></p>
<p id="n244" class="pln"><a href="#n244">244</a></p>
<p id="n245" class="stm mis"><a href="#n245">245</a></p>
<p id="n246" class="stm mis"><a href="#n246">246</a></p>
<p id="n247" class="stm mis"><a href="#n247">247</a></p>
<p id="n248" class="stm mis"><a href="#n248">248</a></p>
<p id="n249" class="stm mis"><a href="#n249">249</a></p>
<p id="n250" class="stm mis"><a href="#n250">250</a></p>
<p id="n251" class="pln"><a href="#n251">251</a></p>
<p id="n252" class="stm mis"><a href="#n252">252</a></p>
<p id="n253" class="stm mis"><a href="#n253">253</a></p>
<p id="n254" class="stm mis"><a href="#n254">254</a></p>
<p id="n255" class="pln"><a href="#n255">255</a></p>
<p id="n256" class="stm mis"><a href="#n256">256</a></p>
<p id="n257" class="stm mis"><a href="#n257">257</a></p>
<p id="n258" class="stm mis"><a href="#n258">258</a></p>
<p id="n259" class="pln"><a href="#n259">259</a></p>
<p id="n260" class="stm mis"><a href="#n260">260</a></p>
<p id="n261" class="stm mis"><a href="#n261">261</a></p>
<p id="n262" class="stm mis"><a href="#n262">262</a></p>
<p id="n263" class="stm mis"><a href="#n263">263</a></p>
<p id="n264" class="pln"><a href="#n264">264</a></p>
<p id="n265" class="stm mis"><a href="#n265">265</a></p>
<p id="n266" class="pln"><a href="#n266">266</a></p>
<p id="n267" class="pln"><a href="#n267">267</a></p>
<p id="n268" class="pln"><a href="#n268">268</a></p>
<p id="n269" class="pln"><a href="#n269">269</a></p>
<p id="n270" class="stm mis"><a href="#n270">270</a></p>
<p id="n271" class="stm mis"><a href="#n271">271</a></p>
<p id="n272" class="pln"><a href="#n272">272</a></p>
<p id="n273" class="stm mis"><a href="#n273">273</a></p>
<p id="n274" class="pln"><a href="#n274">274</a></p>
<p id="n275" class="stm mis"><a href="#n275">275</a></p>
<p id="n276" class="pln"><a href="#n276">276</a></p>
<p id="n277" class="pln"><a href="#n277">277</a></p>
<p id="n278" class="stm mis"><a href="#n278">278</a></p>
<p id="n279" class="stm mis"><a href="#n279">279</a></p>
<p id="n280" class="stm mis"><a href="#n280">280</a></p>
<p id="n281" class="pln"><a href="#n281">281</a></p>
<p id="n282" class="pln"><a href="#n282">282</a></p>
<p id="n283" class="pln"><a href="#n283">283</a></p>
<p id="n284" class="pln"><a href="#n284">284</a></p>
<p id="n285" class="pln"><a href="#n285">285</a></p>
<p id="n286" class="stm mis"><a href="#n286">286</a></p>
<p id="n287" class="pln"><a href="#n287">287</a></p>
<p id="n288" class="pln"><a href="#n288">288</a></p>
<p id="n289" class="pln"><a href="#n289">289</a></p>
<p id="n290" class="pln"><a href="#n290">290</a></p>
<p id="n291" class="stm mis"><a href="#n291">291</a></p>
<p id="n292" class="stm mis"><a href="#n292">292</a></p>
<p id="n293" class="stm mis"><a href="#n293">293</a></p>
<p id="n294" class="stm mis"><a href="#n294">294</a></p>
<p id="n295" class="stm mis"><a href="#n295">295</a></p>
<p id="n296" class="pln"><a href="#n296">296</a></p>
<p id="n297" class="stm mis"><a href="#n297">297</a></p>

            </td>
            <td class="text">
<p id="t1" class="pln"><span class="str">"""ResNet50 model for Keras.</span><span class="strut">&nbsp;</span></p>
<p id="t2" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t3" class="pln"><span class="str"># Reference:</span><span class="strut">&nbsp;</span></p>
<p id="t4" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t5" class="pln"><span class="str">- [Deep Residual Learning for Image Recognition](</span><span class="strut">&nbsp;</span></p>
<p id="t6" class="pln"><span class="str">    https://arxiv.org/abs/1512.03385)</span><span class="strut">&nbsp;</span></p>
<p id="t7" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t8" class="pln"><span class="str">Adapted from code contributed by BigMoyan.</span><span class="strut">&nbsp;</span></p>
<p id="t9" class="pln"><span class="str">"""</span><span class="strut">&nbsp;</span></p>
<p id="t10" class="stm run hide_run"><span class="key">from</span> <span class="nam">__future__</span> <span class="key">import</span> <span class="nam">absolute_import</span><span class="strut">&nbsp;</span></p>
<p id="t11" class="stm run hide_run"><span class="key">from</span> <span class="nam">__future__</span> <span class="key">import</span> <span class="nam">division</span><span class="strut">&nbsp;</span></p>
<p id="t12" class="stm run hide_run"><span class="key">from</span> <span class="nam">__future__</span> <span class="key">import</span> <span class="nam">print_function</span><span class="strut">&nbsp;</span></p>
<p id="t13" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t14" class="stm run hide_run"><span class="key">import</span> <span class="nam">os</span><span class="strut">&nbsp;</span></p>
<p id="t15" class="stm run hide_run"><span class="key">import</span> <span class="nam">warnings</span><span class="strut">&nbsp;</span></p>
<p id="t16" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t17" class="stm run hide_run"><span class="key">from</span> <span class="op">.</span> <span class="key">import</span> <span class="nam">get_submodules_from_kwargs</span><span class="strut">&nbsp;</span></p>
<p id="t18" class="stm run hide_run"><span class="key">from</span> <span class="op">.</span> <span class="key">import</span> <span class="nam">imagenet_utils</span><span class="strut">&nbsp;</span></p>
<p id="t19" class="stm run hide_run"><span class="key">from</span> <span class="op">.</span><span class="nam">imagenet_utils</span> <span class="key">import</span> <span class="nam">decode_predictions</span><span class="strut">&nbsp;</span></p>
<p id="t20" class="stm run hide_run"><span class="key">from</span> <span class="op">.</span><span class="nam">imagenet_utils</span> <span class="key">import</span> <span class="nam">_obtain_input_shape</span><span class="strut">&nbsp;</span></p>
<p id="t21" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t22" class="stm run hide_run"><span class="nam">preprocess_input</span> <span class="op">=</span> <span class="nam">imagenet_utils</span><span class="op">.</span><span class="nam">preprocess_input</span><span class="strut">&nbsp;</span></p>
<p id="t23" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t24" class="stm run hide_run"><span class="nam">WEIGHTS_PATH</span> <span class="op">=</span> <span class="op">(</span><span class="str">'https://github.com/fchollet/deep-learning-models/'</span><span class="strut">&nbsp;</span></p>
<p id="t25" class="pln">                <span class="str">'releases/download/v0.2/'</span><span class="strut">&nbsp;</span></p>
<p id="t26" class="pln">                <span class="str">'resnet50_weights_tf_dim_ordering_tf_kernels.h5'</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t27" class="stm run hide_run"><span class="nam">WEIGHTS_PATH_NO_TOP</span> <span class="op">=</span> <span class="op">(</span><span class="str">'https://github.com/fchollet/deep-learning-models/'</span><span class="strut">&nbsp;</span></p>
<p id="t28" class="pln">                       <span class="str">'releases/download/v0.2/'</span><span class="strut">&nbsp;</span></p>
<p id="t29" class="pln">                       <span class="str">'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t30" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t31" class="stm run hide_run"><span class="nam">backend</span> <span class="op">=</span> <span class="key">None</span><span class="strut">&nbsp;</span></p>
<p id="t32" class="stm run hide_run"><span class="nam">layers</span> <span class="op">=</span> <span class="key">None</span><span class="strut">&nbsp;</span></p>
<p id="t33" class="stm run hide_run"><span class="nam">models</span> <span class="op">=</span> <span class="key">None</span><span class="strut">&nbsp;</span></p>
<p id="t34" class="stm run hide_run"><span class="nam">keras_utils</span> <span class="op">=</span> <span class="key">None</span><span class="strut">&nbsp;</span></p>
<p id="t35" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t36" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t37" class="stm run hide_run"><span class="key">def</span> <span class="nam">identity_block</span><span class="op">(</span><span class="nam">input_tensor</span><span class="op">,</span> <span class="nam">kernel_size</span><span class="op">,</span> <span class="nam">filters</span><span class="op">,</span> <span class="nam">stage</span><span class="op">,</span> <span class="nam">block</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t38" class="pln">    <span class="str">"""The identity block is the block that has no conv layer at shortcut.</span><span class="strut">&nbsp;</span></p>
<p id="t39" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t40" class="pln"><span class="str">    # Arguments</span><span class="strut">&nbsp;</span></p>
<p id="t41" class="pln"><span class="str">        input_tensor: input tensor</span><span class="strut">&nbsp;</span></p>
<p id="t42" class="pln"><span class="str">        kernel_size: default 3, the kernel size of</span><span class="strut">&nbsp;</span></p>
<p id="t43" class="pln"><span class="str">            middle conv layer at main path</span><span class="strut">&nbsp;</span></p>
<p id="t44" class="pln"><span class="str">        filters: list of integers, the filters of 3 conv layer at main path</span><span class="strut">&nbsp;</span></p>
<p id="t45" class="pln"><span class="str">        stage: integer, current stage label, used for generating layer names</span><span class="strut">&nbsp;</span></p>
<p id="t46" class="pln"><span class="str">        block: 'a','b'..., current block label, used for generating layer names</span><span class="strut">&nbsp;</span></p>
<p id="t47" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t48" class="pln"><span class="str">    # Returns</span><span class="strut">&nbsp;</span></p>
<p id="t49" class="pln"><span class="str">        Output tensor for the block.</span><span class="strut">&nbsp;</span></p>
<p id="t50" class="pln"><span class="str">    """</span><span class="strut">&nbsp;</span></p>
<p id="t51" class="stm mis">    <span class="nam">filters1</span><span class="op">,</span> <span class="nam">filters2</span><span class="op">,</span> <span class="nam">filters3</span> <span class="op">=</span> <span class="nam">filters</span><span class="strut">&nbsp;</span></p>
<p id="t52" class="stm mis">    <span class="key">if</span> <span class="nam">backend</span><span class="op">.</span><span class="nam">image_data_format</span><span class="op">(</span><span class="op">)</span> <span class="op">==</span> <span class="str">'channels_last'</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t53" class="stm mis">        <span class="nam">bn_axis</span> <span class="op">=</span> <span class="num">3</span><span class="strut">&nbsp;</span></p>
<p id="t54" class="pln">    <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t55" class="stm mis">        <span class="nam">bn_axis</span> <span class="op">=</span> <span class="num">1</span><span class="strut">&nbsp;</span></p>
<p id="t56" class="stm mis">    <span class="nam">conv_name_base</span> <span class="op">=</span> <span class="str">'res'</span> <span class="op">+</span> <span class="nam">str</span><span class="op">(</span><span class="nam">stage</span><span class="op">)</span> <span class="op">+</span> <span class="nam">block</span> <span class="op">+</span> <span class="str">'_branch'</span><span class="strut">&nbsp;</span></p>
<p id="t57" class="stm mis">    <span class="nam">bn_name_base</span> <span class="op">=</span> <span class="str">'bn'</span> <span class="op">+</span> <span class="nam">str</span><span class="op">(</span><span class="nam">stage</span><span class="op">)</span> <span class="op">+</span> <span class="nam">block</span> <span class="op">+</span> <span class="str">'_branch'</span><span class="strut">&nbsp;</span></p>
<p id="t58" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t59" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">layers</span><span class="op">.</span><span class="nam">Conv2D</span><span class="op">(</span><span class="nam">filters1</span><span class="op">,</span> <span class="op">(</span><span class="num">1</span><span class="op">,</span> <span class="num">1</span><span class="op">)</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t60" class="pln">                      <span class="nam">kernel_initializer</span><span class="op">=</span><span class="str">'he_normal'</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t61" class="pln">                      <span class="nam">name</span><span class="op">=</span><span class="nam">conv_name_base</span> <span class="op">+</span> <span class="str">'2a'</span><span class="op">)</span><span class="op">(</span><span class="nam">input_tensor</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t62" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">layers</span><span class="op">.</span><span class="nam">BatchNormalization</span><span class="op">(</span><span class="nam">axis</span><span class="op">=</span><span class="nam">bn_axis</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="nam">bn_name_base</span> <span class="op">+</span> <span class="str">'2a'</span><span class="op">)</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t63" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">layers</span><span class="op">.</span><span class="nam">Activation</span><span class="op">(</span><span class="str">'relu'</span><span class="op">)</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t64" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t65" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">layers</span><span class="op">.</span><span class="nam">Conv2D</span><span class="op">(</span><span class="nam">filters2</span><span class="op">,</span> <span class="nam">kernel_size</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t66" class="pln">                      <span class="nam">padding</span><span class="op">=</span><span class="str">'same'</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t67" class="pln">                      <span class="nam">kernel_initializer</span><span class="op">=</span><span class="str">'he_normal'</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t68" class="pln">                      <span class="nam">name</span><span class="op">=</span><span class="nam">conv_name_base</span> <span class="op">+</span> <span class="str">'2b'</span><span class="op">)</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t69" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">layers</span><span class="op">.</span><span class="nam">BatchNormalization</span><span class="op">(</span><span class="nam">axis</span><span class="op">=</span><span class="nam">bn_axis</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="nam">bn_name_base</span> <span class="op">+</span> <span class="str">'2b'</span><span class="op">)</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t70" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">layers</span><span class="op">.</span><span class="nam">Activation</span><span class="op">(</span><span class="str">'relu'</span><span class="op">)</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t71" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t72" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">layers</span><span class="op">.</span><span class="nam">Conv2D</span><span class="op">(</span><span class="nam">filters3</span><span class="op">,</span> <span class="op">(</span><span class="num">1</span><span class="op">,</span> <span class="num">1</span><span class="op">)</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t73" class="pln">                      <span class="nam">kernel_initializer</span><span class="op">=</span><span class="str">'he_normal'</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t74" class="pln">                      <span class="nam">name</span><span class="op">=</span><span class="nam">conv_name_base</span> <span class="op">+</span> <span class="str">'2c'</span><span class="op">)</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t75" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">layers</span><span class="op">.</span><span class="nam">BatchNormalization</span><span class="op">(</span><span class="nam">axis</span><span class="op">=</span><span class="nam">bn_axis</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="nam">bn_name_base</span> <span class="op">+</span> <span class="str">'2c'</span><span class="op">)</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t76" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t77" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">layers</span><span class="op">.</span><span class="nam">add</span><span class="op">(</span><span class="op">[</span><span class="nam">x</span><span class="op">,</span> <span class="nam">input_tensor</span><span class="op">]</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t78" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">layers</span><span class="op">.</span><span class="nam">Activation</span><span class="op">(</span><span class="str">'relu'</span><span class="op">)</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t79" class="stm mis">    <span class="key">return</span> <span class="nam">x</span><span class="strut">&nbsp;</span></p>
<p id="t80" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t81" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t82" class="stm run hide_run"><span class="key">def</span> <span class="nam">conv_block</span><span class="op">(</span><span class="nam">input_tensor</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t83" class="pln">               <span class="nam">kernel_size</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t84" class="pln">               <span class="nam">filters</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t85" class="pln">               <span class="nam">stage</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t86" class="pln">               <span class="nam">block</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t87" class="pln">               <span class="nam">strides</span><span class="op">=</span><span class="op">(</span><span class="num">2</span><span class="op">,</span> <span class="num">2</span><span class="op">)</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t88" class="pln">    <span class="str">"""A block that has a conv layer at shortcut.</span><span class="strut">&nbsp;</span></p>
<p id="t89" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t90" class="pln"><span class="str">    # Arguments</span><span class="strut">&nbsp;</span></p>
<p id="t91" class="pln"><span class="str">        input_tensor: input tensor</span><span class="strut">&nbsp;</span></p>
<p id="t92" class="pln"><span class="str">        kernel_size: default 3, the kernel size of</span><span class="strut">&nbsp;</span></p>
<p id="t93" class="pln"><span class="str">            middle conv layer at main path</span><span class="strut">&nbsp;</span></p>
<p id="t94" class="pln"><span class="str">        filters: list of integers, the filters of 3 conv layer at main path</span><span class="strut">&nbsp;</span></p>
<p id="t95" class="pln"><span class="str">        stage: integer, current stage label, used for generating layer names</span><span class="strut">&nbsp;</span></p>
<p id="t96" class="pln"><span class="str">        block: 'a','b'..., current block label, used for generating layer names</span><span class="strut">&nbsp;</span></p>
<p id="t97" class="pln"><span class="str">        strides: Strides for the first conv layer in the block.</span><span class="strut">&nbsp;</span></p>
<p id="t98" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t99" class="pln"><span class="str">    # Returns</span><span class="strut">&nbsp;</span></p>
<p id="t100" class="pln"><span class="str">        Output tensor for the block.</span><span class="strut">&nbsp;</span></p>
<p id="t101" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t102" class="pln"><span class="str">    Note that from stage 3,</span><span class="strut">&nbsp;</span></p>
<p id="t103" class="pln"><span class="str">    the first conv layer at main path is with strides=(2, 2)</span><span class="strut">&nbsp;</span></p>
<p id="t104" class="pln"><span class="str">    And the shortcut should have strides=(2, 2) as well</span><span class="strut">&nbsp;</span></p>
<p id="t105" class="pln"><span class="str">    """</span><span class="strut">&nbsp;</span></p>
<p id="t106" class="stm mis">    <span class="nam">filters1</span><span class="op">,</span> <span class="nam">filters2</span><span class="op">,</span> <span class="nam">filters3</span> <span class="op">=</span> <span class="nam">filters</span><span class="strut">&nbsp;</span></p>
<p id="t107" class="stm mis">    <span class="key">if</span> <span class="nam">backend</span><span class="op">.</span><span class="nam">image_data_format</span><span class="op">(</span><span class="op">)</span> <span class="op">==</span> <span class="str">'channels_last'</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t108" class="stm mis">        <span class="nam">bn_axis</span> <span class="op">=</span> <span class="num">3</span><span class="strut">&nbsp;</span></p>
<p id="t109" class="pln">    <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t110" class="stm mis">        <span class="nam">bn_axis</span> <span class="op">=</span> <span class="num">1</span><span class="strut">&nbsp;</span></p>
<p id="t111" class="stm mis">    <span class="nam">conv_name_base</span> <span class="op">=</span> <span class="str">'res'</span> <span class="op">+</span> <span class="nam">str</span><span class="op">(</span><span class="nam">stage</span><span class="op">)</span> <span class="op">+</span> <span class="nam">block</span> <span class="op">+</span> <span class="str">'_branch'</span><span class="strut">&nbsp;</span></p>
<p id="t112" class="stm mis">    <span class="nam">bn_name_base</span> <span class="op">=</span> <span class="str">'bn'</span> <span class="op">+</span> <span class="nam">str</span><span class="op">(</span><span class="nam">stage</span><span class="op">)</span> <span class="op">+</span> <span class="nam">block</span> <span class="op">+</span> <span class="str">'_branch'</span><span class="strut">&nbsp;</span></p>
<p id="t113" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t114" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">layers</span><span class="op">.</span><span class="nam">Conv2D</span><span class="op">(</span><span class="nam">filters1</span><span class="op">,</span> <span class="op">(</span><span class="num">1</span><span class="op">,</span> <span class="num">1</span><span class="op">)</span><span class="op">,</span> <span class="nam">strides</span><span class="op">=</span><span class="nam">strides</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t115" class="pln">                      <span class="nam">kernel_initializer</span><span class="op">=</span><span class="str">'he_normal'</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t116" class="pln">                      <span class="nam">name</span><span class="op">=</span><span class="nam">conv_name_base</span> <span class="op">+</span> <span class="str">'2a'</span><span class="op">)</span><span class="op">(</span><span class="nam">input_tensor</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t117" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">layers</span><span class="op">.</span><span class="nam">BatchNormalization</span><span class="op">(</span><span class="nam">axis</span><span class="op">=</span><span class="nam">bn_axis</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="nam">bn_name_base</span> <span class="op">+</span> <span class="str">'2a'</span><span class="op">)</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t118" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">layers</span><span class="op">.</span><span class="nam">Activation</span><span class="op">(</span><span class="str">'relu'</span><span class="op">)</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t119" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t120" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">layers</span><span class="op">.</span><span class="nam">Conv2D</span><span class="op">(</span><span class="nam">filters2</span><span class="op">,</span> <span class="nam">kernel_size</span><span class="op">,</span> <span class="nam">padding</span><span class="op">=</span><span class="str">'same'</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t121" class="pln">                      <span class="nam">kernel_initializer</span><span class="op">=</span><span class="str">'he_normal'</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t122" class="pln">                      <span class="nam">name</span><span class="op">=</span><span class="nam">conv_name_base</span> <span class="op">+</span> <span class="str">'2b'</span><span class="op">)</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t123" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">layers</span><span class="op">.</span><span class="nam">BatchNormalization</span><span class="op">(</span><span class="nam">axis</span><span class="op">=</span><span class="nam">bn_axis</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="nam">bn_name_base</span> <span class="op">+</span> <span class="str">'2b'</span><span class="op">)</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t124" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">layers</span><span class="op">.</span><span class="nam">Activation</span><span class="op">(</span><span class="str">'relu'</span><span class="op">)</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t125" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t126" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">layers</span><span class="op">.</span><span class="nam">Conv2D</span><span class="op">(</span><span class="nam">filters3</span><span class="op">,</span> <span class="op">(</span><span class="num">1</span><span class="op">,</span> <span class="num">1</span><span class="op">)</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t127" class="pln">                      <span class="nam">kernel_initializer</span><span class="op">=</span><span class="str">'he_normal'</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t128" class="pln">                      <span class="nam">name</span><span class="op">=</span><span class="nam">conv_name_base</span> <span class="op">+</span> <span class="str">'2c'</span><span class="op">)</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t129" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">layers</span><span class="op">.</span><span class="nam">BatchNormalization</span><span class="op">(</span><span class="nam">axis</span><span class="op">=</span><span class="nam">bn_axis</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="nam">bn_name_base</span> <span class="op">+</span> <span class="str">'2c'</span><span class="op">)</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t130" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t131" class="stm mis">    <span class="nam">shortcut</span> <span class="op">=</span> <span class="nam">layers</span><span class="op">.</span><span class="nam">Conv2D</span><span class="op">(</span><span class="nam">filters3</span><span class="op">,</span> <span class="op">(</span><span class="num">1</span><span class="op">,</span> <span class="num">1</span><span class="op">)</span><span class="op">,</span> <span class="nam">strides</span><span class="op">=</span><span class="nam">strides</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t132" class="pln">                             <span class="nam">kernel_initializer</span><span class="op">=</span><span class="str">'he_normal'</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t133" class="pln">                             <span class="nam">name</span><span class="op">=</span><span class="nam">conv_name_base</span> <span class="op">+</span> <span class="str">'1'</span><span class="op">)</span><span class="op">(</span><span class="nam">input_tensor</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t134" class="stm mis">    <span class="nam">shortcut</span> <span class="op">=</span> <span class="nam">layers</span><span class="op">.</span><span class="nam">BatchNormalization</span><span class="op">(</span><span class="strut">&nbsp;</span></p>
<p id="t135" class="pln">        <span class="nam">axis</span><span class="op">=</span><span class="nam">bn_axis</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="nam">bn_name_base</span> <span class="op">+</span> <span class="str">'1'</span><span class="op">)</span><span class="op">(</span><span class="nam">shortcut</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t136" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t137" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">layers</span><span class="op">.</span><span class="nam">add</span><span class="op">(</span><span class="op">[</span><span class="nam">x</span><span class="op">,</span> <span class="nam">shortcut</span><span class="op">]</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t138" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">layers</span><span class="op">.</span><span class="nam">Activation</span><span class="op">(</span><span class="str">'relu'</span><span class="op">)</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t139" class="stm mis">    <span class="key">return</span> <span class="nam">x</span><span class="strut">&nbsp;</span></p>
<p id="t140" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t141" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t142" class="stm run hide_run"><span class="key">def</span> <span class="nam">ResNet50</span><span class="op">(</span><span class="nam">include_top</span><span class="op">=</span><span class="key">True</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t143" class="pln">             <span class="nam">weights</span><span class="op">=</span><span class="str">'imagenet'</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t144" class="pln">             <span class="nam">input_tensor</span><span class="op">=</span><span class="key">None</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t145" class="pln">             <span class="nam">input_shape</span><span class="op">=</span><span class="key">None</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t146" class="pln">             <span class="nam">pooling</span><span class="op">=</span><span class="key">None</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t147" class="pln">             <span class="nam">classes</span><span class="op">=</span><span class="num">1000</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t148" class="pln">             <span class="op">**</span><span class="nam">kwargs</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t149" class="pln">    <span class="str">"""Instantiates the ResNet50 architecture.</span><span class="strut">&nbsp;</span></p>
<p id="t150" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t151" class="pln"><span class="str">    Optionally loads weights pre-trained on ImageNet.</span><span class="strut">&nbsp;</span></p>
<p id="t152" class="pln"><span class="str">    Note that the data format convention used by the model is</span><span class="strut">&nbsp;</span></p>
<p id="t153" class="pln"><span class="str">    the one specified in your Keras config at `~/.keras/keras.json`.</span><span class="strut">&nbsp;</span></p>
<p id="t154" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t155" class="pln"><span class="str">    # Arguments</span><span class="strut">&nbsp;</span></p>
<p id="t156" class="pln"><span class="str">        include_top: whether to include the fully-connected</span><span class="strut">&nbsp;</span></p>
<p id="t157" class="pln"><span class="str">            layer at the top of the network.</span><span class="strut">&nbsp;</span></p>
<p id="t158" class="pln"><span class="str">        weights: one of `None` (random initialization),</span><span class="strut">&nbsp;</span></p>
<p id="t159" class="pln"><span class="str">              'imagenet' (pre-training on ImageNet),</span><span class="strut">&nbsp;</span></p>
<p id="t160" class="pln"><span class="str">              or the path to the weights file to be loaded.</span><span class="strut">&nbsp;</span></p>
<p id="t161" class="pln"><span class="str">        input_tensor: optional Keras tensor (i.e. output of `layers.Input()`)</span><span class="strut">&nbsp;</span></p>
<p id="t162" class="pln"><span class="str">            to use as image input for the model.</span><span class="strut">&nbsp;</span></p>
<p id="t163" class="pln"><span class="str">        input_shape: optional shape tuple, only to be specified</span><span class="strut">&nbsp;</span></p>
<p id="t164" class="pln"><span class="str">            if `include_top` is False (otherwise the input shape</span><span class="strut">&nbsp;</span></p>
<p id="t165" class="pln"><span class="str">            has to be `(224, 224, 3)` (with `channels_last` data format)</span><span class="strut">&nbsp;</span></p>
<p id="t166" class="pln"><span class="str">            or `(3, 224, 224)` (with `channels_first` data format).</span><span class="strut">&nbsp;</span></p>
<p id="t167" class="pln"><span class="str">            It should have exactly 3 inputs channels,</span><span class="strut">&nbsp;</span></p>
<p id="t168" class="pln"><span class="str">            and width and height should be no smaller than 197.</span><span class="strut">&nbsp;</span></p>
<p id="t169" class="pln"><span class="str">            E.g. `(200, 200, 3)` would be one valid value.</span><span class="strut">&nbsp;</span></p>
<p id="t170" class="pln"><span class="str">        pooling: Optional pooling mode for feature extraction</span><span class="strut">&nbsp;</span></p>
<p id="t171" class="pln"><span class="str">            when `include_top` is `False`.</span><span class="strut">&nbsp;</span></p>
<p id="t172" class="pln"><span class="str">            - `None` means that the output of the model will be</span><span class="strut">&nbsp;</span></p>
<p id="t173" class="pln"><span class="str">                the 4D tensor output of the</span><span class="strut">&nbsp;</span></p>
<p id="t174" class="pln"><span class="str">                last convolutional layer.</span><span class="strut">&nbsp;</span></p>
<p id="t175" class="pln"><span class="str">            - `avg` means that global average pooling</span><span class="strut">&nbsp;</span></p>
<p id="t176" class="pln"><span class="str">                will be applied to the output of the</span><span class="strut">&nbsp;</span></p>
<p id="t177" class="pln"><span class="str">                last convolutional layer, and thus</span><span class="strut">&nbsp;</span></p>
<p id="t178" class="pln"><span class="str">                the output of the model will be a 2D tensor.</span><span class="strut">&nbsp;</span></p>
<p id="t179" class="pln"><span class="str">            - `max` means that global max pooling will</span><span class="strut">&nbsp;</span></p>
<p id="t180" class="pln"><span class="str">                be applied.</span><span class="strut">&nbsp;</span></p>
<p id="t181" class="pln"><span class="str">        classes: optional number of classes to classify images</span><span class="strut">&nbsp;</span></p>
<p id="t182" class="pln"><span class="str">            into, only to be specified if `include_top` is True, and</span><span class="strut">&nbsp;</span></p>
<p id="t183" class="pln"><span class="str">            if no `weights` argument is specified.</span><span class="strut">&nbsp;</span></p>
<p id="t184" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t185" class="pln"><span class="str">    # Returns</span><span class="strut">&nbsp;</span></p>
<p id="t186" class="pln"><span class="str">        A Keras model instance.</span><span class="strut">&nbsp;</span></p>
<p id="t187" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t188" class="pln"><span class="str">    # Raises</span><span class="strut">&nbsp;</span></p>
<p id="t189" class="pln"><span class="str">        ValueError: in case of invalid argument for `weights`,</span><span class="strut">&nbsp;</span></p>
<p id="t190" class="pln"><span class="str">            or invalid input shape.</span><span class="strut">&nbsp;</span></p>
<p id="t191" class="pln"><span class="str">    """</span><span class="strut">&nbsp;</span></p>
<p id="t192" class="pln">    <span class="key">global</span> <span class="nam">backend</span><span class="op">,</span> <span class="nam">layers</span><span class="op">,</span> <span class="nam">models</span><span class="op">,</span> <span class="nam">keras_utils</span><span class="strut">&nbsp;</span></p>
<p id="t193" class="stm mis">    <span class="nam">backend</span><span class="op">,</span> <span class="nam">layers</span><span class="op">,</span> <span class="nam">models</span><span class="op">,</span> <span class="nam">keras_utils</span> <span class="op">=</span> <span class="nam">get_submodules_from_kwargs</span><span class="op">(</span><span class="nam">kwargs</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t194" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t195" class="stm mis">    <span class="key">if</span> <span class="key">not</span> <span class="op">(</span><span class="nam">weights</span> <span class="key">in</span> <span class="op">{</span><span class="str">'imagenet'</span><span class="op">,</span> <span class="key">None</span><span class="op">}</span> <span class="key">or</span> <span class="nam">os</span><span class="op">.</span><span class="nam">path</span><span class="op">.</span><span class="nam">exists</span><span class="op">(</span><span class="nam">weights</span><span class="op">)</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t196" class="stm mis">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">'The `weights` argument should be either '</span><span class="strut">&nbsp;</span></p>
<p id="t197" class="pln">                         <span class="str">'`None` (random initialization), `imagenet` '</span><span class="strut">&nbsp;</span></p>
<p id="t198" class="pln">                         <span class="str">'(pre-training on ImageNet), '</span><span class="strut">&nbsp;</span></p>
<p id="t199" class="pln">                         <span class="str">'or the path to the weights file to be loaded.'</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t200" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t201" class="stm mis">    <span class="key">if</span> <span class="nam">weights</span> <span class="op">==</span> <span class="str">'imagenet'</span> <span class="key">and</span> <span class="nam">include_top</span> <span class="key">and</span> <span class="nam">classes</span> <span class="op">!=</span> <span class="num">1000</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t202" class="stm mis">        <span class="key">raise</span> <span class="nam">ValueError</span><span class="op">(</span><span class="str">'If using `weights` as `"imagenet"` with `include_top`'</span><span class="strut">&nbsp;</span></p>
<p id="t203" class="pln">                         <span class="str">' as true, `classes` should be 1000'</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t204" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t205" class="pln">    <span class="com"># Determine proper input shape</span><span class="strut">&nbsp;</span></p>
<p id="t206" class="stm mis">    <span class="nam">input_shape</span> <span class="op">=</span> <span class="nam">_obtain_input_shape</span><span class="op">(</span><span class="nam">input_shape</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t207" class="pln">                                      <span class="nam">default_size</span><span class="op">=</span><span class="num">224</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t208" class="pln">                                      <span class="nam">min_size</span><span class="op">=</span><span class="num">32</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t209" class="pln">                                      <span class="nam">data_format</span><span class="op">=</span><span class="nam">backend</span><span class="op">.</span><span class="nam">image_data_format</span><span class="op">(</span><span class="op">)</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t210" class="pln">                                      <span class="nam">require_flatten</span><span class="op">=</span><span class="nam">include_top</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t211" class="pln">                                      <span class="nam">weights</span><span class="op">=</span><span class="nam">weights</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t212" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t213" class="stm mis">    <span class="key">if</span> <span class="nam">input_tensor</span> <span class="key">is</span> <span class="key">None</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t214" class="stm mis">        <span class="nam">img_input</span> <span class="op">=</span> <span class="nam">layers</span><span class="op">.</span><span class="nam">Input</span><span class="op">(</span><span class="nam">shape</span><span class="op">=</span><span class="nam">input_shape</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t215" class="pln">    <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t216" class="stm mis">        <span class="key">if</span> <span class="key">not</span> <span class="nam">backend</span><span class="op">.</span><span class="nam">is_keras_tensor</span><span class="op">(</span><span class="nam">input_tensor</span><span class="op">)</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t217" class="stm mis">            <span class="nam">img_input</span> <span class="op">=</span> <span class="nam">layers</span><span class="op">.</span><span class="nam">Input</span><span class="op">(</span><span class="nam">tensor</span><span class="op">=</span><span class="nam">input_tensor</span><span class="op">,</span> <span class="nam">shape</span><span class="op">=</span><span class="nam">input_shape</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t218" class="pln">        <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t219" class="stm mis">            <span class="nam">img_input</span> <span class="op">=</span> <span class="nam">input_tensor</span><span class="strut">&nbsp;</span></p>
<p id="t220" class="stm mis">    <span class="key">if</span> <span class="nam">backend</span><span class="op">.</span><span class="nam">image_data_format</span><span class="op">(</span><span class="op">)</span> <span class="op">==</span> <span class="str">'channels_last'</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t221" class="stm mis">        <span class="nam">bn_axis</span> <span class="op">=</span> <span class="num">3</span><span class="strut">&nbsp;</span></p>
<p id="t222" class="pln">    <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t223" class="stm mis">        <span class="nam">bn_axis</span> <span class="op">=</span> <span class="num">1</span><span class="strut">&nbsp;</span></p>
<p id="t224" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t225" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">layers</span><span class="op">.</span><span class="nam">ZeroPadding2D</span><span class="op">(</span><span class="nam">padding</span><span class="op">=</span><span class="op">(</span><span class="num">3</span><span class="op">,</span> <span class="num">3</span><span class="op">)</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="str">'conv1_pad'</span><span class="op">)</span><span class="op">(</span><span class="nam">img_input</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t226" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">layers</span><span class="op">.</span><span class="nam">Conv2D</span><span class="op">(</span><span class="num">64</span><span class="op">,</span> <span class="op">(</span><span class="num">7</span><span class="op">,</span> <span class="num">7</span><span class="op">)</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t227" class="pln">                      <span class="nam">strides</span><span class="op">=</span><span class="op">(</span><span class="num">2</span><span class="op">,</span> <span class="num">2</span><span class="op">)</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t228" class="pln">                      <span class="nam">padding</span><span class="op">=</span><span class="str">'valid'</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t229" class="pln">                      <span class="nam">kernel_initializer</span><span class="op">=</span><span class="str">'he_normal'</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t230" class="pln">                      <span class="nam">name</span><span class="op">=</span><span class="str">'conv1'</span><span class="op">)</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t231" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">layers</span><span class="op">.</span><span class="nam">BatchNormalization</span><span class="op">(</span><span class="nam">axis</span><span class="op">=</span><span class="nam">bn_axis</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="str">'bn_conv1'</span><span class="op">)</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t232" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">layers</span><span class="op">.</span><span class="nam">Activation</span><span class="op">(</span><span class="str">'relu'</span><span class="op">)</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t233" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">layers</span><span class="op">.</span><span class="nam">ZeroPadding2D</span><span class="op">(</span><span class="nam">padding</span><span class="op">=</span><span class="op">(</span><span class="num">1</span><span class="op">,</span> <span class="num">1</span><span class="op">)</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="str">'pool1_pad'</span><span class="op">)</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t234" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">layers</span><span class="op">.</span><span class="nam">MaxPooling2D</span><span class="op">(</span><span class="op">(</span><span class="num">3</span><span class="op">,</span> <span class="num">3</span><span class="op">)</span><span class="op">,</span> <span class="nam">strides</span><span class="op">=</span><span class="op">(</span><span class="num">2</span><span class="op">,</span> <span class="num">2</span><span class="op">)</span><span class="op">)</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t235" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t236" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">conv_block</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="num">3</span><span class="op">,</span> <span class="op">[</span><span class="num">64</span><span class="op">,</span> <span class="num">64</span><span class="op">,</span> <span class="num">256</span><span class="op">]</span><span class="op">,</span> <span class="nam">stage</span><span class="op">=</span><span class="num">2</span><span class="op">,</span> <span class="nam">block</span><span class="op">=</span><span class="str">'a'</span><span class="op">,</span> <span class="nam">strides</span><span class="op">=</span><span class="op">(</span><span class="num">1</span><span class="op">,</span> <span class="num">1</span><span class="op">)</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t237" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">identity_block</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="num">3</span><span class="op">,</span> <span class="op">[</span><span class="num">64</span><span class="op">,</span> <span class="num">64</span><span class="op">,</span> <span class="num">256</span><span class="op">]</span><span class="op">,</span> <span class="nam">stage</span><span class="op">=</span><span class="num">2</span><span class="op">,</span> <span class="nam">block</span><span class="op">=</span><span class="str">'b'</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t238" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">identity_block</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="num">3</span><span class="op">,</span> <span class="op">[</span><span class="num">64</span><span class="op">,</span> <span class="num">64</span><span class="op">,</span> <span class="num">256</span><span class="op">]</span><span class="op">,</span> <span class="nam">stage</span><span class="op">=</span><span class="num">2</span><span class="op">,</span> <span class="nam">block</span><span class="op">=</span><span class="str">'c'</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t239" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t240" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">conv_block</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="num">3</span><span class="op">,</span> <span class="op">[</span><span class="num">128</span><span class="op">,</span> <span class="num">128</span><span class="op">,</span> <span class="num">512</span><span class="op">]</span><span class="op">,</span> <span class="nam">stage</span><span class="op">=</span><span class="num">3</span><span class="op">,</span> <span class="nam">block</span><span class="op">=</span><span class="str">'a'</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t241" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">identity_block</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="num">3</span><span class="op">,</span> <span class="op">[</span><span class="num">128</span><span class="op">,</span> <span class="num">128</span><span class="op">,</span> <span class="num">512</span><span class="op">]</span><span class="op">,</span> <span class="nam">stage</span><span class="op">=</span><span class="num">3</span><span class="op">,</span> <span class="nam">block</span><span class="op">=</span><span class="str">'b'</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t242" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">identity_block</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="num">3</span><span class="op">,</span> <span class="op">[</span><span class="num">128</span><span class="op">,</span> <span class="num">128</span><span class="op">,</span> <span class="num">512</span><span class="op">]</span><span class="op">,</span> <span class="nam">stage</span><span class="op">=</span><span class="num">3</span><span class="op">,</span> <span class="nam">block</span><span class="op">=</span><span class="str">'c'</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t243" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">identity_block</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="num">3</span><span class="op">,</span> <span class="op">[</span><span class="num">128</span><span class="op">,</span> <span class="num">128</span><span class="op">,</span> <span class="num">512</span><span class="op">]</span><span class="op">,</span> <span class="nam">stage</span><span class="op">=</span><span class="num">3</span><span class="op">,</span> <span class="nam">block</span><span class="op">=</span><span class="str">'d'</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t244" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t245" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">conv_block</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="num">3</span><span class="op">,</span> <span class="op">[</span><span class="num">256</span><span class="op">,</span> <span class="num">256</span><span class="op">,</span> <span class="num">1024</span><span class="op">]</span><span class="op">,</span> <span class="nam">stage</span><span class="op">=</span><span class="num">4</span><span class="op">,</span> <span class="nam">block</span><span class="op">=</span><span class="str">'a'</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t246" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">identity_block</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="num">3</span><span class="op">,</span> <span class="op">[</span><span class="num">256</span><span class="op">,</span> <span class="num">256</span><span class="op">,</span> <span class="num">1024</span><span class="op">]</span><span class="op">,</span> <span class="nam">stage</span><span class="op">=</span><span class="num">4</span><span class="op">,</span> <span class="nam">block</span><span class="op">=</span><span class="str">'b'</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t247" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">identity_block</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="num">3</span><span class="op">,</span> <span class="op">[</span><span class="num">256</span><span class="op">,</span> <span class="num">256</span><span class="op">,</span> <span class="num">1024</span><span class="op">]</span><span class="op">,</span> <span class="nam">stage</span><span class="op">=</span><span class="num">4</span><span class="op">,</span> <span class="nam">block</span><span class="op">=</span><span class="str">'c'</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t248" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">identity_block</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="num">3</span><span class="op">,</span> <span class="op">[</span><span class="num">256</span><span class="op">,</span> <span class="num">256</span><span class="op">,</span> <span class="num">1024</span><span class="op">]</span><span class="op">,</span> <span class="nam">stage</span><span class="op">=</span><span class="num">4</span><span class="op">,</span> <span class="nam">block</span><span class="op">=</span><span class="str">'d'</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t249" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">identity_block</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="num">3</span><span class="op">,</span> <span class="op">[</span><span class="num">256</span><span class="op">,</span> <span class="num">256</span><span class="op">,</span> <span class="num">1024</span><span class="op">]</span><span class="op">,</span> <span class="nam">stage</span><span class="op">=</span><span class="num">4</span><span class="op">,</span> <span class="nam">block</span><span class="op">=</span><span class="str">'e'</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t250" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">identity_block</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="num">3</span><span class="op">,</span> <span class="op">[</span><span class="num">256</span><span class="op">,</span> <span class="num">256</span><span class="op">,</span> <span class="num">1024</span><span class="op">]</span><span class="op">,</span> <span class="nam">stage</span><span class="op">=</span><span class="num">4</span><span class="op">,</span> <span class="nam">block</span><span class="op">=</span><span class="str">'f'</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t251" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t252" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">conv_block</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="num">3</span><span class="op">,</span> <span class="op">[</span><span class="num">512</span><span class="op">,</span> <span class="num">512</span><span class="op">,</span> <span class="num">2048</span><span class="op">]</span><span class="op">,</span> <span class="nam">stage</span><span class="op">=</span><span class="num">5</span><span class="op">,</span> <span class="nam">block</span><span class="op">=</span><span class="str">'a'</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t253" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">identity_block</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="num">3</span><span class="op">,</span> <span class="op">[</span><span class="num">512</span><span class="op">,</span> <span class="num">512</span><span class="op">,</span> <span class="num">2048</span><span class="op">]</span><span class="op">,</span> <span class="nam">stage</span><span class="op">=</span><span class="num">5</span><span class="op">,</span> <span class="nam">block</span><span class="op">=</span><span class="str">'b'</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t254" class="stm mis">    <span class="nam">x</span> <span class="op">=</span> <span class="nam">identity_block</span><span class="op">(</span><span class="nam">x</span><span class="op">,</span> <span class="num">3</span><span class="op">,</span> <span class="op">[</span><span class="num">512</span><span class="op">,</span> <span class="num">512</span><span class="op">,</span> <span class="num">2048</span><span class="op">]</span><span class="op">,</span> <span class="nam">stage</span><span class="op">=</span><span class="num">5</span><span class="op">,</span> <span class="nam">block</span><span class="op">=</span><span class="str">'c'</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t255" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t256" class="stm mis">    <span class="key">if</span> <span class="nam">include_top</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t257" class="stm mis">        <span class="nam">x</span> <span class="op">=</span> <span class="nam">layers</span><span class="op">.</span><span class="nam">GlobalAveragePooling2D</span><span class="op">(</span><span class="nam">name</span><span class="op">=</span><span class="str">'avg_pool'</span><span class="op">)</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t258" class="stm mis">        <span class="nam">x</span> <span class="op">=</span> <span class="nam">layers</span><span class="op">.</span><span class="nam">Dense</span><span class="op">(</span><span class="nam">classes</span><span class="op">,</span> <span class="nam">activation</span><span class="op">=</span><span class="str">'softmax'</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="str">'fc1000'</span><span class="op">)</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t259" class="pln">    <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t260" class="stm mis">        <span class="key">if</span> <span class="nam">pooling</span> <span class="op">==</span> <span class="str">'avg'</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t261" class="stm mis">            <span class="nam">x</span> <span class="op">=</span> <span class="nam">layers</span><span class="op">.</span><span class="nam">GlobalAveragePooling2D</span><span class="op">(</span><span class="op">)</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t262" class="stm mis">        <span class="key">elif</span> <span class="nam">pooling</span> <span class="op">==</span> <span class="str">'max'</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t263" class="stm mis">            <span class="nam">x</span> <span class="op">=</span> <span class="nam">layers</span><span class="op">.</span><span class="nam">GlobalMaxPooling2D</span><span class="op">(</span><span class="op">)</span><span class="op">(</span><span class="nam">x</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t264" class="pln">        <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t265" class="stm mis">            <span class="nam">warnings</span><span class="op">.</span><span class="nam">warn</span><span class="op">(</span><span class="str">'The output shape of `ResNet50(include_top=False)` '</span><span class="strut">&nbsp;</span></p>
<p id="t266" class="pln">                          <span class="str">'has been changed since Keras 2.2.0.'</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t267" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t268" class="pln">    <span class="com"># Ensure that the model takes into account</span><span class="strut">&nbsp;</span></p>
<p id="t269" class="pln">    <span class="com"># any potential predecessors of `input_tensor`.</span><span class="strut">&nbsp;</span></p>
<p id="t270" class="stm mis">    <span class="key">if</span> <span class="nam">input_tensor</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t271" class="stm mis">        <span class="nam">inputs</span> <span class="op">=</span> <span class="nam">keras_utils</span><span class="op">.</span><span class="nam">get_source_inputs</span><span class="op">(</span><span class="nam">input_tensor</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t272" class="pln">    <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t273" class="stm mis">        <span class="nam">inputs</span> <span class="op">=</span> <span class="nam">img_input</span><span class="strut">&nbsp;</span></p>
<p id="t274" class="pln">    <span class="com"># Create model.</span><span class="strut">&nbsp;</span></p>
<p id="t275" class="stm mis">    <span class="nam">model</span> <span class="op">=</span> <span class="nam">models</span><span class="op">.</span><span class="nam">Model</span><span class="op">(</span><span class="nam">inputs</span><span class="op">,</span> <span class="nam">x</span><span class="op">,</span> <span class="nam">name</span><span class="op">=</span><span class="str">'resnet50'</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t276" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t277" class="pln">    <span class="com"># Load weights.</span><span class="strut">&nbsp;</span></p>
<p id="t278" class="stm mis">    <span class="key">if</span> <span class="nam">weights</span> <span class="op">==</span> <span class="str">'imagenet'</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t279" class="stm mis">        <span class="key">if</span> <span class="nam">include_top</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t280" class="stm mis">            <span class="nam">weights_path</span> <span class="op">=</span> <span class="nam">keras_utils</span><span class="op">.</span><span class="nam">get_file</span><span class="op">(</span><span class="strut">&nbsp;</span></p>
<p id="t281" class="pln">                <span class="str">'resnet50_weights_tf_dim_ordering_tf_kernels.h5'</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t282" class="pln">                <span class="nam">WEIGHTS_PATH</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t283" class="pln">                <span class="nam">cache_subdir</span><span class="op">=</span><span class="str">'models'</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t284" class="pln">                <span class="nam">md5_hash</span><span class="op">=</span><span class="str">'a7b3fe01876f51b976af0dea6bc144eb'</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t285" class="pln">        <span class="key">else</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t286" class="stm mis">            <span class="nam">weights_path</span> <span class="op">=</span> <span class="nam">keras_utils</span><span class="op">.</span><span class="nam">get_file</span><span class="op">(</span><span class="strut">&nbsp;</span></p>
<p id="t287" class="pln">                <span class="str">'resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t288" class="pln">                <span class="nam">WEIGHTS_PATH_NO_TOP</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t289" class="pln">                <span class="nam">cache_subdir</span><span class="op">=</span><span class="str">'models'</span><span class="op">,</span><span class="strut">&nbsp;</span></p>
<p id="t290" class="pln">                <span class="nam">md5_hash</span><span class="op">=</span><span class="str">'a268eb855778b3df3c7506639542a6af'</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t291" class="stm mis">        <span class="nam">model</span><span class="op">.</span><span class="nam">load_weights</span><span class="op">(</span><span class="nam">weights_path</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t292" class="stm mis">        <span class="key">if</span> <span class="nam">backend</span><span class="op">.</span><span class="nam">backend</span><span class="op">(</span><span class="op">)</span> <span class="op">==</span> <span class="str">'theano'</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t293" class="stm mis">            <span class="nam">keras_utils</span><span class="op">.</span><span class="nam">convert_all_kernels_in_model</span><span class="op">(</span><span class="nam">model</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t294" class="stm mis">    <span class="key">elif</span> <span class="nam">weights</span> <span class="key">is</span> <span class="key">not</span> <span class="key">None</span><span class="op">:</span><span class="strut">&nbsp;</span></p>
<p id="t295" class="stm mis">        <span class="nam">model</span><span class="op">.</span><span class="nam">load_weights</span><span class="op">(</span><span class="nam">weights</span><span class="op">)</span><span class="strut">&nbsp;</span></p>
<p id="t296" class="pln"><span class="strut">&nbsp;</span></p>
<p id="t297" class="stm mis">    <span class="key">return</span> <span class="nam">model</span><span class="strut">&nbsp;</span></p>

            </td>
        </tr>
    </table>
</div>

<div id="footer">
    <div class="content">
        <p>
            <a class="nav" href="index.html">&#xab; index</a> &nbsp; &nbsp; <a class="nav" href="https://coverage.readthedocs.io">coverage.py v4.5.2</a>,
            created at 2018-12-27 22:42
        </p>
    </div>
</div>

</body>
</html>
